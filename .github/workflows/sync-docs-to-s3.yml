name: Sync Katalon Docs to S3 and Trigger Bedrock Ingestion

on:
  push:
    paths:
      - "docs/**"
      - ".github/workflows/**"
    branches: [master]
  workflow_call:
    inputs:
      doc-path: # "./docs"
        required: true
        type: string

    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      AWS_REGION:
        required: true
      DOCS_S3_BUCKET_ID:
        required: true
      KNOWLEDGE_BASE_ID:
        required: true
      DOCS_DATA_SOURCE_ID:
        required: true

jobs:
  sync-and-ingest:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v4

      - name: Generate metadata files
        run: |
          accessLevel=1
          find ${{ inputs.doc-path }} -type f -name "*.md" | while read file; do
            rel_path=${file#${{ inputs.doc-path }}/}
            folder=$(dirname "$rel_path")
            filename=$(basename "$file" .md)
            
            cat > "${file}.metadata.json" << EOF
          {
              "metadataAttributes": {
                  "access_level": $accessLevel,
                  "url": "https://docs.katalon.com/${folder}/${filename}"
              }
          }
          EOF
            echo "Generated metadata for $rel_path"
          done

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Sync to S3
        run: |
          aws s3 sync ${{ inputs.doc-path }} s3://${{ secrets.DOCS_S3_BUCKET_ID }}/docs/ --size-only --delete

      - name: Trigger Bedrock ingestion
        run: |
          max_attempts=5
          attempt=1
          while [ $attempt -le $max_attempts ]; do
            echo "Attempt $attempt of $max_attempts..."
            if aws bedrock-agent start-ingestion-job \
              --knowledge-base-id ${{ secrets.KNOWLEDGE_BASE_ID }} \
              --data-source-id ${{ secrets.DOCS_DATA_SOURCE_ID }}; then
              echo "Ingestion job started successfully"
              break
            else
              if [ $attempt -eq $max_attempts ]; then
                echo "Failed to start ingestion job after $max_attempts attempts"
                exit 1
              else
                echo "Attempt $attempt failed, retrying in 30 seconds..."
                sleep 30
                ((attempt++))
              fi
            fi
          done
