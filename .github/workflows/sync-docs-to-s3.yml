name: Sync Docs to S3 and Trigger Bedrock Ingestion

on:
  push:
    paths:
      - "docs/**"
      - ".github/workflows/**"
    branches: [master]

jobs:
  sync-and-ingest:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Sync to S3
        run: |
          aws s3 sync ./docs/ s3://${{ secrets.DOCS_S3_BUCKET_ID }}/ --delete

      - name: Trigger Bedrock ingestion
        run: |
          max_attempts=5
          attempt=1
          while [ $attempt -le $max_attempts ]; do
            echo "Attempt $attempt of $max_attempts..."
            if aws bedrock-agent start-ingestion-job \
              --knowledge-base-id ${{ secrets.KNOWLEDGE_BASE_ID }} \
              --data-source-id ${{ secrets.DOCS_DATA_SOURCE_ID }}; then
              echo "Ingestion job started successfully"
              break
            else
              if [ $attempt -eq $max_attempts ]; then
                echo "Failed to start ingestion job after $max_attempts attempts"
                exit 1
              else
                echo "Attempt $attempt failed, retrying in 30 seconds..."
                sleep 30
                ((attempt++))
              fi
            fi
          done
